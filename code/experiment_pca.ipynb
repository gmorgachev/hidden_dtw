{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from time import time\n",
    "from os import listdir, path\n",
    "\n",
    "from numpy.random import choice, shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "from dtaidistance import dtw, dtw_c, dtw_ndim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import preprocessing\n",
    "import utils\n",
    "from models import Encoder, DecoderLinear, DecoderLSTM, Sequence2Sequence\n",
    "\n",
    "%aimport preprocessing\n",
    "%aimport models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "BASE_PATH = \"../data/Univariate_arff\"\n",
    "TRAIN = \"_TRAIN\"\n",
    "TEST = \"_TEST\"\n",
    "\n",
    "BIG_CONST = 100000\n",
    "datasets = [name for name in listdir(BASE_PATH) if path.isdir(path.join(BASE_PATH, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/length_Univariate_arff.json\") as f:\n",
    "    lengths = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 3\n",
    "k = 3\n",
    "hidden_dim = 3\n",
    "sample_size = 300\n",
    "\n",
    "results = {name: {} for name in datasets}\n",
    "try:\n",
    "    for idx, problem in enumerate([name for name in datasets if lengths[name] < 200]):    \n",
    "        length = lengths[problem]\n",
    "        data_path = path.join(BASE_PATH, problem, problem)    \n",
    "        pca = PCA(n_components=hidden_dim)\n",
    "        X, y = preprocessing.get_dataset(data_path, length=length)\n",
    "\n",
    "        X = X[:sample_size]\n",
    "        y = y[:sample_size]\n",
    "        train_set, test_set, valid_set = preprocessing.prepare_data(X, y, k, w, device)\n",
    "        train_it = iter(train_set)\n",
    "        for batch, _, _ in train_it:\n",
    "            for x in batch.cpu().detach().numpy():\n",
    "                pca = pca.fit(x)\n",
    "\n",
    "        valid_it = iter(valid_set)\n",
    "        batch, timeseries, labels = next(valid_it)\n",
    "        batch = batch.cpu().detach().numpy()\n",
    "        timeseries = timeseries.numpy()\n",
    "        idxs = np.arange(len(timeseries)).reshape(-1, 1)\n",
    "\n",
    "        scores_hidden = []\n",
    "        scores_ts = []\n",
    "        t = time()\n",
    "        hiddens = np.stack([pca.transform(x) for x in batch])\n",
    "\n",
    "        print(problem, batch.shape[0])\n",
    "        scores_ts, scores_hidden = utils.classify(timeseries, hiddens, labels)\n",
    "        results[problem][\"ts\"] = scores_ts\n",
    "        results[problem][\"hidden\"] = scores_hidden\n",
    "        results[problem][\"shape\"] = X.shape\n",
    "        results[problem][\"balance\"] = np.unique(y, return_counts=True)\n",
    "        print()\n",
    "\n",
    "    with open(\"results_pca.json\", \"w\") as f:\n",
    "        json.dump(results, f, cls=utils.NumpyEncoder)\n",
    "\n",
    "except Exception as exc:\n",
    "    with open(\"results_pca.json\", \"w\") as f:\n",
    "        json.dump(results, f, cls=utils.NumpyEncoder)\n",
    "\n",
    "    raise exc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "* Select $sample\\_size$ items of length $n$ from dataset .\n",
    "* Split into train, test, valid.  \n",
    "    P.S.: *Now valid set is unused.*\n",
    "    \n",
    "* Split each ts into sequence of small time-series  \n",
    "    **Parameters**\n",
    "    * $w$: shift size\n",
    "    * $k$: 2*k - window size \n",
    "    * $h$: hidden dimension, dimension of each point after encoding\n",
    "    \n",
    "    The length of new sequence:\n",
    "$$l = \\dfrac{n-2k}{w} + 1 $$\n",
    "    Encoder: \n",
    "$$\n",
    " \\mathbf{R}^{l\\times 2k} \\rightarrow \\mathbf{R}^{l\\times h}\n",
    "$$\n",
    "    \n",
    "* Train autoencoder or PCA on train test.\n",
    "* Encode valid set\n",
    "* Calculate distance matrix. (c engine is used only for univariate ts. So, we can't directly compare times)\n",
    "* Classify hiddens and raw time series via KNN classifier.\n",
    "    * Split valid dataset into classify_train, classify_test. Classify_test size = 0.7 * valid size.\n",
    "    * KNN with k = 3 now.\n",
    "    * Repeat many times\n",
    "      \n",
    "\n",
    "## PCA\n",
    "* Valid size = $20\\%$ of sample size.\n",
    "* Train size = $75\\%$ of sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |       Problem        | N items | Length | Raw ts score | Hidden score \n",
      "----------------------------------------------------------------------------\n",
      "  0 |                ACSF1 |     300 |     50 | 0.95 +- 0.01 | 0.94 +- 0.01 \n",
      "  1 |                Adiac |     300 |    175 | 0.31 +- 0.04 | 0.26 +- 0.03 \n",
      "  2 |   AllGestureWiimoteX |     300 |    115 | 0.46 +- 0.04 | 0.47 +- 0.04 \n",
      "  3 |   AllGestureWiimoteY |     300 |    115 | 0.47 +- 0.03 | 0.49 +- 0.03 \n",
      "  4 |   AllGestureWiimoteZ |     300 |    115 | 0.43 +- 0.04 | 0.41 +- 0.04 \n",
      "  5 |            BeetleFly |     120 |    150 | 0.59 +- 0.05 | 0.58 +- 0.05 \n",
      "  6 |                  BME |     180 |    128 | 0.93 +- 0.04 | 0.99 +- 0.03 \n",
      "  7 |                  CBF |     300 |    128 | 1.00 +- 0.00 | 1.00 +- 0.01 \n",
      "  8 |            Chinatown |     300 |     24 | 0.97 +- 0.01 | 0.97 +- 0.01 \n",
      "  9 | ChlorineConcentratio |     300 |    150 | 0.45 +- 0.04 | 0.45 +- 0.04 \n",
      " 10 |                 Crop |     300 |     46 | 1.00 +- 0.00 | 1.00 +- 0.00 \n",
      " 11 | DistalPhalanxOutline |     300 |     80 | 0.65 +- 0.03 | 0.64 +- 0.03 \n",
      " 12 | DistalPhalanxOutline |     300 |     80 | 0.70 +- 0.04 | 0.68 +- 0.04 \n",
      " 13 |      DistalPhalanxTW |     300 |     80 | 0.71 +- 0.03 | 0.70 +- 0.03 \n",
      " 14 |               ECG200 |     200 |     95 | 0.76 +- 0.05 | 0.79 +- 0.05 \n",
      " 15 |              ECG5000 |     300 |    140 | 1.00 +- 0.00 | 1.00 +- 0.00 \n",
      " 16 |          ECGFiveDays |     300 |    135 | 0.86 +- 0.03 | 0.81 +- 0.03 \n",
      " 17 |      ElectricDevices |     300 |     96 | 0.75 +- 0.04 | 0.73 +- 0.04 \n",
      " 18 |              FaceAll |     300 |    130 | 0.99 +- 0.01 | 0.99 +- 0.00 \n",
      " 19 |             FacesUCR |     300 |    130 | 0.65 +- 0.05 | 0.62 +- 0.04 \n",
      " 20 |      GestureMidAirD1 |     300 |     85 | 0.13 +- 0.02 | 0.12 +- 0.03 \n",
      " 21 |      GestureMidAirD2 |     300 |     85 | 0.11 +- 0.02 | 0.11 +- 0.02 \n",
      " 22 |      GestureMidAirD3 |     300 |     85 | 0.10 +- 0.02 | 0.10 +- 0.02 \n",
      " 23 |      GesturePebbleZ1 |     168 |    190 | 0.47 +- 0.05 | 0.49 +- 0.05 \n",
      " 24 |             GunPoint |     200 |    150 | 0.83 +- 0.04 | 0.94 +- 0.03 \n",
      " 25 |      GunPointAgeSpan |     300 |    150 | 0.84 +- 0.03 | 0.94 +- 0.02 \n",
      " 26 | GunPointMaleVersusFe |     300 |    150 | 0.99 +- 0.01 | 0.99 +- 0.01 \n",
      " 27 | GunPointOldVersusYou |     300 |    150 | 0.78 +- 0.04 | 0.86 +- 0.04 \n",
      " 28 |     ItalyPowerDemand |     300 |     24 | 0.91 +- 0.02 | 0.94 +- 0.02 \n",
      " 29 |        MedicalImages |     300 |     99 | 0.52 +- 0.04 | 0.52 +- 0.04 \n",
      " 30 |  MelbournePedestrian |     300 |     24 | 0.97 +- 0.01 | 0.97 +- 0.01 \n",
      " 31 | MiddlePhalanxOutline |     300 |     80 | 0.49 +- 0.04 | 0.50 +- 0.05 \n",
      " 32 | MiddlePhalanxOutline |     300 |     80 | 0.70 +- 0.03 | 0.73 +- 0.03 \n",
      " 33 |      MiddlePhalanxTW |     300 |     80 | 0.57 +- 0.03 | 0.56 +- 0.03 \n",
      " 34 |           MoteStrain |     300 |     80 | 0.82 +- 0.03 | 0.83 +- 0.02 \n",
      " 35 | PhalangesOutlinesCor |     300 |     80 | 0.68 +- 0.03 | 0.66 +- 0.03 \n",
      " 36 | PickupGestureWiimote |      60 |    131 | 0.30 +- 0.08 | 0.35 +- 0.09 \n",
      " 37 |                Plane |     210 |    144 | 0.99 +- 0.03 | 0.99 +- 0.03 \n",
      " 38 |            PowerCons |     300 |    144 | 0.78 +- 0.03 | 0.81 +- 0.03 \n",
      " 39 | ProximalPhalanxOutli |     300 |     80 | 0.76 +- 0.03 | 0.76 +- 0.02 \n",
      " 40 | ProximalPhalanxOutli |     300 |     80 | 0.74 +- 0.03 | 0.75 +- 0.03 \n",
      " 41 |    ProximalPhalanxTW |     300 |     80 | 0.73 +- 0.03 | 0.73 +- 0.03 \n",
      " 42 | ShakeGestureWiimoteZ |      66 |    140 | 0.44 +- 0.10 | 0.49 +- 0.12 \n",
      " 43 |          ShapeletSim |     300 |    150 | 0.86 +- 0.02 | 0.87 +- 0.02 \n",
      " 44 |       SmoothSubspace |     300 |     15 | 0.82 +- 0.04 | 0.72 +- 0.03 \n",
      " 45 | SonyAIBORobotSurface |     300 |     70 | 0.93 +- 0.03 | 0.93 +- 0.03 \n",
      " 46 | SonyAIBORobotSurface |     300 |     65 | 0.86 +- 0.03 | 0.88 +- 0.03 \n",
      " 47 |          SwedishLeaf |     300 |    127 | 0.62 +- 0.05 | 0.61 +- 0.04 \n",
      " 48 |     SyntheticControl |     300 |     60 | 0.98 +- 0.01 | 0.97 +- 0.01 \n",
      " 49 |           TwoLeadECG |     300 |     82 | 0.97 +- 0.02 | 0.92 +- 0.03 \n",
      " 50 |          TwoPatterns |     300 |    128 | 0.99 +- 0.01 | 0.99 +- 0.02 \n",
      " 51 |                  UMD |     180 |    150 | 0.95 +- 0.05 | 0.92 +- 0.05 \n",
      " 52 |                Wafer |     300 |    150 | 0.92 +- 0.02 | 0.91 +- 0.02 \n"
     ]
    }
   ],
   "source": [
    "with open(\"results_pca.json\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "    \n",
    "header = \"{0:3s} | {1:^20s} | {2:^7s} | {3:^6s} | {4:^12s} | {5:^12s} \".format(\n",
    "    \"\", \"Problem\", \"N items\", \"Length\", \"Raw ts score\", \"Hidden score\")\n",
    "print(header)\n",
    "print(\"-\"*len(header))\n",
    "\n",
    "for idx, problem in enumerate([name for name in datasets if lengths[name] < 200]):    \n",
    "    length = lengths[problem]\n",
    "    print(\"{:3d} | {:>20s} | {:7d} | {:6d} | {:.2f} +- {:.2f} | {:.2f} +- {:.2f} \".format(\n",
    "        idx, problem[:20],\n",
    "        results[problem][\"shape\"][0],\n",
    "        results[problem][\"shape\"][1],\n",
    "        np.mean(results[problem][\"ts\"]), np.std(results[problem][\"ts\"]),\n",
    "        np.mean(results[problem][\"hidden\"]), np.std(results[problem][\"hidden\"]),    \n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hidden_dtw",
   "language": "python",
   "name": "hidden_dtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
