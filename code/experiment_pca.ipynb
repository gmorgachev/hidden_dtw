{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from time import time\n",
    "from os import listdir, path\n",
    "\n",
    "from numpy.random import choice, shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import zscore\n",
    "from dtaidistance import dtw, dtw_c, dtw_ndim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import preprocessing\n",
    "import utils\n",
    "from models import Encoder, DecoderLinear, DecoderLSTM, Sequence2Sequence\n",
    "\n",
    "%aimport preprocessing\n",
    "%aimport models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "BASE_PATH = \"../data/Univariate_arff\"\n",
    "TRAIN = \"_TRAIN\"\n",
    "TEST = \"_TEST\"\n",
    "\n",
    "BIG_CONST = 100000\n",
    "datasets = [name for name in listdir(BASE_PATH) if path.isdir(path.join(BASE_PATH, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/length_Univariate_arff.json\") as f:\n",
    "    lengths = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACSF1\n",
      "hidden_ts: 19.805\n",
      "raw_ts: 32.107\n",
      "Raw ts score: 1.000 +- 0.000\n",
      "Hidden ts score: 1.000 +- 0.000\n",
      "\n",
      "Adiac\n",
      "hidden_ts: 271.242\n"
     ]
    }
   ],
   "source": [
    "w = 3\n",
    "k = 3\n",
    "hidden_dim = 3\n",
    "sample_size = 150\n",
    "\n",
    "results = {name: {} for name in datasets}\n",
    "try:\n",
    "    for idx, problem in enumerate([name for name in datasets if lengths[name] < 200]):    \n",
    "        length = lengths[problem]\n",
    "        data_path = path.join(BASE_PATH, problem, problem)    \n",
    "        pca = PCA(n_components=hidden_dim)\n",
    "        X, y = preprocessing.get_dataset(data_path, length=length)\n",
    "\n",
    "        X = X[:sample_size]\n",
    "        y = y[:sample_size]\n",
    "        train_set, test_set, valid_set = preprocessing.prepare_data(X, y, k, w, device)\n",
    "        train_it = iter(train_set)\n",
    "        for batch, _, _ in train_it:\n",
    "            for x in batch.cpu().detach().numpy():\n",
    "                pca = pca.fit(x)\n",
    "\n",
    "        valid_it = iter(valid_set)\n",
    "        batch, timeseries, labels = next(valid_it)\n",
    "        batch = batch.cpu().detach().numpy()\n",
    "        timeseries = timeseries.numpy()\n",
    "        idxs = np.arange(len(timeseries)).reshape(-1, 1)\n",
    "\n",
    "        scores_hidden = []\n",
    "        scores_ts = []\n",
    "        t = time()\n",
    "        hiddens = np.stack([pca.transform(x) for x in batch])\n",
    "\n",
    "        print(problem)\n",
    "        scores_ts, scores_hidden = utils.classify(timeseries, hiddens, labels)\n",
    "        results[problem][\"ts\"] = scores_ts\n",
    "        results[problem][\"hidden\"] = scores_hidden\n",
    "        results[problem][\"shape\"] = X.shape\n",
    "        results[problem][\"balance\"] = np.unique(y, return_counts=True)\n",
    "        print()\n",
    "\n",
    "        with open(\"results.json\", \"w\") as f:\n",
    "            json.dump(lengths, f)\n",
    "\n",
    "except Exception as exc:\n",
    "    with open(\"results.json\", \"w\") as f:\n",
    "        json.dump(lengths, f)\n",
    "\n",
    "    raise exc\n",
    "\n",
    "# header = \"{0:3s} | {1:^20s} | {2:^4s} | {3:^4s}\".format(\"\", \"Problem\", \"Items\", \"Length\")\n",
    "# print(header)\n",
    "# print(\"-\"*len(header))   \n",
    "# print(\"{0:3d} | {1:>20s} | {2:5d} | {3:6d}\".format(\n",
    "#     idx, problem[:20], X.shape[0], X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hidden_dtw",
   "language": "python",
   "name": "hidden_dtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
