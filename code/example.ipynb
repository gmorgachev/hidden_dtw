{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from dtaidistance import dtw, dtw_c, dtw_ndim\n",
    "from numpy.random import choice, shuffle\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "from preprocessing import *\n",
    "from models import Encoder, Decoder, Sequence2Sequence\n",
    "\n",
    "%aimport preprocessing\n",
    "%aimport models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of multidimensional time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir -p data\n",
    "# !wget https://www.cs.ucr.edu/%7Eeamonn/time_series_data_2018/UCRArchive_2018.zip ../data\n",
    "# !unzip data/UCRArchive_2018.zip -d ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../data/UCRArchive_2018/Earthquakes/Earthquakes_TRAIN.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(data_path, header=None, delimiter=\"\\t\").values\n",
    "\n",
    "# # to remove Nan (only first columns)\n",
    "# data = data[:, ~np.isnan(data).any(0)]\n",
    "\n",
    "# X = data[:, 1:]\n",
    "# y = data[:, 0].astype(np.short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerometer dataset \n",
    "\n",
    "- 1: Working at Computer\n",
    "- 2: Standing Up, Walking and Going up\\down stairs\n",
    "- 3: Standing\n",
    "- 4: Walking\n",
    "- 5: Going Up\\Down Stairs\n",
    "- 6: Walking and Talking with Someone\n",
    "- 7: Talking while Standing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00287/Activity%20Recognition%20from%20Single%20Chest-Mounted%20Accelerometer.zip -O ../data/Accelerometer.zip\n",
    "# ! unzip ../data/Accelerometer.zip -d ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/Activity Recognition from Single Chest-Mounted Accelerometer/1.csv\"\n",
    "CHANNELS = ['0', '1', '2']\n",
    "LABELS = [1, 4, 5, 6]\n",
    "LENGTH = 50\n",
    "start_ident = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path,\n",
    "                   names=['0', '1', '2', \"labels\"],\n",
    "                   index_col=0,\n",
    "                   dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "dataset = {}\n",
    "for label in LABELS:\n",
    "    X = get_class_timeseries(label, data, start_ident)\n",
    "    X = np.linalg.norm(X, axis=1)[np.newaxis].T\n",
    "    dataset[label] = slice_timeseries(X, LENGTH, count=45)\n",
    "    \n",
    "\n",
    "X = [x for _, ts in dataset.items() for x in ts]\n",
    "y = [np.repeat(label, ts.shape[0]) for label, ts in dataset.items() for x in ts]\n",
    "X = np.hstack(X).T\n",
    "y = np.hstack(y).T\n",
    "\n",
    "idxs = list(range(X.shape[0]))\n",
    "shuffle(idxs)\n",
    "\n",
    "X = X[idxs]\n",
    "y = y[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 4\n",
    "k = 4\n",
    "\n",
    "input_dim = 2*k\n",
    "hidden_dim = 5\n",
    "n_layers = 3\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [split_to_sequence(x, k, w) for x in X[choice(len(X), batch_size)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor(sequences, dtype=torch.float).permute(1, 0, 2).cuda()\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_dim, hidden_dim, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he = torch.randn(n_layers, batch_size, hidden_dim, dtype=torch.float).cuda()\n",
    "ce = torch.randn(n_layers, batch_size, hidden_dim, dtype=torch.float).cuda()\n",
    "\n",
    "hd = torch.randn(n_layers, batch_size, input_dim, dtype=torch.float).cuda()\n",
    "cd = torch.randn(n_layers, batch_size, input_dim, dtype=torch.float).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Encoder, Decoder, Sequence2Sequence\n",
    "enc = Encoder(input_dim, hidden_dim, 1, 1, 3)\n",
    "dec = Decoder(hidden_dim, input_dim, 1, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequence2Sequence(enc, dec)\n",
    "model.to(torch.device(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optim = torch.optim.Adam(model.parameters(), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEP = 1000\n",
    "\n",
    "def train(model, batch):\n",
    "    model.train()\n",
    "    for step in range(N_STEP):\n",
    "        out = model(batch, he, ce, hd, cd)\n",
    "        loss = loss_fn(batch, out)\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(\"Loss:\", loss)\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "def valid(model, batch):\n",
    "    model.eval()\n",
    "    out = model(batch, he, ce, hd, cd)\n",
    "    loss = loss_fn(batch, out)\n",
    "    \n",
    "    print(\"Valid loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.valid()\n",
    "train(model, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hidden_dtw",
   "language": "python",
   "name": "hidden_dtw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
